{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'empirenews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month = '02'\n",
    "days = [str(i) for i in list(range(18,29))]\n",
    "\n",
    "dates = []\n",
    "for day in days:\n",
    "    if len(day)<2:\n",
    "        day = \"0{}\".format(day)\n",
    "    dates.append(\"{0}-{1}\".format(month, day))\n",
    "    \n",
    "month='03'\n",
    "days = [str(i) for i in list(range(1,14))]\n",
    "\n",
    "for day in days:\n",
    "    if len(day)<2:\n",
    "        day = \"0{}\".format(day)\n",
    "    dates.append(\"{0}-{1}\".format(month, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n",
      "File not found\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    # Load HTML\n",
    "    filepath = '/ebs_volume/data/notCredible/{0}/{1}.html'.format(source,date)\n",
    "    try:\n",
    "        with open(filepath) as f:\n",
    "            soup = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "        # Pull out article links\n",
    "        links = []\n",
    "        i=0\n",
    "\n",
    "        for p in soup.findAll('p', attrs={\"class\":\"date\"}):\n",
    "            pubdate = str(datetime.strptime(p.text, \"%B %d, %Y\"))\n",
    "            if date in pubdate:\n",
    "                for header in soup.findAll('h2'):\n",
    "                    for link in header.findAll('a'):\n",
    "                        links.append(link.get('href'))\n",
    "\n",
    "        links = set(links)\n",
    "        links = list(links)\n",
    "\n",
    "        for link in links:\n",
    "            link = newspaper.Article(link)\n",
    "            link.download()\n",
    "            html = link.html\n",
    "            link.parse()\n",
    "            date_longform = '{0}-2017'.format(date)\n",
    "            title = link.title.replace('Infostormer.Com   |  ', '')\n",
    "\n",
    "            article = {}\n",
    "            article[\"html\"] = html\n",
    "            article[\"title\"] = title\n",
    "            article[\"url\"] = link.url\n",
    "            article[\"date\"] = date_longform\n",
    "            article[\"source\"] = source\n",
    "            article[\"text\"] = link.text\n",
    "            article[\"images\"] = list(link.images)\n",
    "            article[\"videos\"] = link.movies\n",
    "\n",
    "            outfile = '/ebs_volume/data/notCredible/{0}/articles/{1}/article{2}.txt'.format(source,date,i)\n",
    "            os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "            i+=1\n",
    "\n",
    "            with open(outfile, 'w') as f:\n",
    "                json.dump(article, f)\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test that articles saved correctly\n",
    "with open('/mnt/c/Users/Brennan/Dropbox/MIDS/w210-capstone/data/notCredible/infostormer/articles/03-07/article0_03-07.txt') as json_data:\n",
    "    d = json.load(json_data)\n",
    "    \n",
    "print(d[\"title\"])\n",
    "print()\n",
    "print(d[\"source\"])\n",
    "print()\n",
    "print(d[\"url\"])\n",
    "print()\n",
    "print(d[\"date\"])\n",
    "print()\n",
    "print(d[\"text\"])\n",
    "print()\n",
    "print(d[\"images\"])\n",
    "print()\n",
    "print(d[\"videos\"])\n",
    "print()\n",
    "print(d[\"html\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
